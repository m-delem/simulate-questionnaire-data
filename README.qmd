---
title: Simulating Likert-type questionnaire data with R  
author: " "
format: gfm
---

<img src="images/likert.png" align="left" width="200"/>

I have been working on multiple projects that involved analysing questionnaires with "Likert scales", i.e. ordinal variables or pseudo-continuous variables obtained by summing all the ordinal items. Before engaging into the experiments proper, we should conduct robust power analyses, code testing, sanity checks, etc. to ensure that the data collection and analysis will be as smooth as possible. In several complex settings such as multivariate analyses or multilevel modelling, simulation can be a powerful tool to do these tasks by allowing to test intricate computations on synthetic data.

> I found out (*after the deed, of course*) that several packages already existed that could have eased my work. The closest to what I coded here is the [`LikertMakeR`](https://github.com/WinzarH/LikertMakeR) package, which is really comprehensive. Also check out [`latent2likert`](https://github.com/markolalovic/latent2likert) for a more item-based simulation approach. Note: this is not a standalone package because I don't think the functions add a signficant improvement over those from the packages above, but I like the straightforward solutions I came up with, which is why I document them here. *(I still added them to [my (secret ðŸ‘€) personal package](https://github.com/m-delem/delemr/) though, to access them quickly without copy-pasting.)*

```{r}
#| label: setup
#| output: false

source("scripts/simulate_questionnaires.R")
source("scripts/plot_questionnaires.R")
```

## Simulate items for a given score

My initial problem was to find a way to simulate a fixed number of bounded ordinal variables (questionnaire items) that sum to a given score. I wanted to be able to simulate the score distributions of a whole population on a multi-item questionnaire based on literature or assumptions, ***then*** simulate individual items making up the scale (which is the reverse process of more "item-based" approaches like [`latent2likert`](https://github.com/markolalovic/latent2likert)). This resulted in the `simulate_items` function[^1]: given a score, a number of items, a minimum and a maximum value, it returns a vector of simulated items.

[^1]: The function is close in its purpose to the `makeItemsScale` from the `LikertMakeR` package.

```{r}
#| label: simulate-items

# Subject with a score of 32 on a 12-item questionnaire ranging from 1 to 5
simulate_items(score = 32, n_items = 12, min_item = 1, max_item = 5)

# Subject with a score of 35 on a 8-item questionnaire ranging from 1 to 7
simulate_items(35, 8, 1, 7, verbose = TRUE)
```

It can be mapped on a distribution to simulate the items for a whole sample of subjects.

```{r}
#| label: simulate-multiple

n_subjects <- 1000

# Normal distribution of scores
df <- 
  tibble(
    subject = 1:n_subjects,
    score = rnorm(n_subjects, mean = 32, sd = 5) |> round()
  ) |>
  rowwise() |> 
  mutate(item = list(simulate_items(score, 12, 1, 5))) |> 
  unnest_wider(item, names_sep = "_")

df |> head() |> display()
```

On this basis, I created the `simulate_questionnaires` function to simulate the scores of a questionnaire for a given number of subjects. The function can simulate multiple scales in parallel with normal or skew-normal distributions, which can be correlated. Conceptually, this could be a simulation of multiple correlated questionnaires (Q1 with several items on a construct correlated with Q2 on another construct) or a questionnaire with correlated sub-scales... Or both at the same time, just name your scales however you want.

```{r}
#| label: simulate-questionnaires

# Let's see if we can simulate the OSIVQ
df_osivq <- 
  simulate_questionnaires(
    n_subjects = 1000,
    names = c("osivq_o", "osivq_s", "osivq_v"),  
    distrib = c("skew_normal", "normal", "normal"), 
    method = "item_means",
    means = c(3.63, 2.83, 3),   
    sds = c(0.62, 0.66, 0.68),       
    skews = c(-0.392, 0, 0),
    corrs = c(-0.03, 0.12, -0.18),
    n_items = c(15, 15, 15),
    min_item = c(1, 1, 1),
    max_item = c(5, 5, 5),
    add_items = FALSE,
    print_corrs = TRUE
    )
```

```{r}
#| label: plot-questionnaires
#| fig-width: 8
#| fig-height: 6

plot_questionnaires(osivq, var = "score", questionnaire = "OSIVQ", print = TRUE)
plot_questionnaires(osivq, var = "mean", questionnaire = "OSIVQ", print = TRUE)
```

<!-- It shows methods to: -->

<!-- -   Simulate score distributions from various types of information (e.g., quantile percentages, means, sd, skewness). -->

<!-- -   Simulate different distributions for sub-scales or sub-groups in the sample. -->

<!-- -   Correlate sub-scales with different types of distributions. -->

<!-- -   Simulate individual ordinal items from the total scores of each subject. -->

The simulation script (`scripts/simulate_questionnaires.R`) is heavily commented to explain the rationale behind the code and the choices made. The script is also designed to be easily adaptable to other questionnaires. `scripts/plot_questionnaires.R` contains two functions associated with the questionnaires to provide convenient plotting methods.

## VVIQ and OSIVQ

This repository also contains code to simulate data from two mental imagery questionnaires I used often: the [Vividness of Visual Imagery Questionnaire (VVIQ)](https://bpspsychub.onlinelibrary.wiley.com/doi/10.1111/j.2044-8295.1973.tb01322.x) and the [Object-Spatial Imagery and Verbal Questionnaire](https://onlinelibrary.wiley.com/doi/10.1002/acp.1473).

`simulate_vviq` creates a data frame with a given number of subjects, simulating VVIQ scores and mean scores for four groups defined in aphantasia literature (aphantasia, hypophantasia, typical imagery and hyperphantasia, see [Wright et al., 2024](<https://www.frontiersin.org/journals/psychology/articles/10.3389/fpsyg.2024.1454107/full>)). It can optionally simulate individual responses for all of the 16 items of the VVIQ for each subject (all responses of course summing to the simulated score).

```{r}
#| label: simulate-vviq

df_vviq <- simulate_vviq(n_subjects = 1000, add_items = TRUE)

df_vviq |> 
  group_by(group) |> 
  slice(1) |> 
  display()
```

`simulate_osivq` does the same for the OSIVQ, which comprises three sub-scales: Object, Spatial and Verbal. There are no conventional thresholds to define groups for this questionnaire.

```{r}
#| label: simulate-osivq

df_osivq <- simulate_osivq(n_subjects = 1000, add_items = TRUE)

df_osivq |> 
  head() |> 
  display()
```

Two plotting functions, `plot_vviq` and `plot_osivq`, are provided to plot the distributions of the scores and means of the VVIQ and OSIVQ, respectively. They can be called with the argument `print = TRUE` to display the plot directly in the console. In any case, they return a ggplot object that can be further customized.

```{r}
#| label: plot_vviq
#| fig-width: 14
#| fig-height: 9

vviq_scores <- df_vviq |> plot_vviq(var = "score", print = FALSE)
vviq_means  <- df_vviq |> plot_vviq(var = "mean", print = FALSE) + 
  labs(title = NULL, y = NULL)

osivq_scores <- df_osivq |> plot_osivq(var = "score", print = FALSE)
osivq_means  <- df_osivq |> plot_osivq(var = "mean", print = FALSE) + 
  labs(title = NULL, y = NULL)

# Laying out the four plots with the `patchwork` package
(vviq_scores + vviq_means) / (osivq_scores + osivq_means) + 
  plot_layout(guides = "collect")
```

I believe the structures presented in these scripts could be useful to anyone who needs to simulate Likert-type questionnaire data. The scripts are designed to be easily adaptable to other questionnaires and can be used as templates to build your own simulation scripts. I hope they will be useful to you! :cherry_blossom:

> Note: this repository is a Quarto project endowed with a `renv` R environment to ensure the stability of the packages used. The repository is based on [this Quarto project template](https://github.com/m-delem/my-quarto-template): you can find a quick tutorial to use this project structure and an in-depth explanation of its elements in the README of the template.
